{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "# Assuming the dataset is stored in 'cnc_data.csv' with features and a target column named 'failure'\n",
    "data = pd.read_csv('cnc_data.csv')\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('failure', axis=1)\n",
    "y = data['failure']\n",
    "\n",
    "# Split the dataset into training and testing sets using stratification\n",
    "# Stratification ensures that the rare failure events are proportionally represented in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42)  # Enable probability estimates for ROC AUC\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results for each model\n",
    "results = {}\n",
    "\n",
    "# Loop over the models, train them, and compute evaluation metrics\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)  # Recall is critical as it minimizes false negatives\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate ROC AUC if probability estimates or decision function is available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_probs)\n",
    "    else:\n",
    "        try:\n",
    "            y_scores = model.decision_function(X_test)\n",
    "            roc_auc = roc_auc_score(y_test, y_scores)\n",
    "        except:\n",
    "            roc_auc = None\n",
    "    \n",
    "    # Store the computed metrics\n",
    "    results[name] = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'ROC AUC': roc_auc\n",
    "    }\n",
    "\n",
    "# Convert the results dictionary to a DataFrame for easier comparison\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Since recall is the priority in this imbalanced scenario, sort the results by Recall\n",
    "results_df.sort_values(by='Recall', ascending=False, inplace=True)\n",
    "\n",
    "# Display the summary results\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
